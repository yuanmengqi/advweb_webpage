<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AdvWeb</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.svg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                  <span class="author-block">
                  <a href="https://xuchejian.com/" target="_blank">Chejian Xu</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                  <a href="https://kangmintong.github.io/" target="_blank">Mintong Kang</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://javyduck.github.io/" target="_blank">Jiawei Zhang</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://lzy37ld.github.io/" target="_blank">Zeyi Liao</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://molingbo.github.io/" target="_blank">Lingbo Mo</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://yuanmengqi.github.io/" target="_blank">Mengqi Yuan</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://u.osu.edu/ihudas/people/" target="_blank">Huan Sun</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://aisecure.github.io/" target="_blank">Bo Li</a><sup>1</sup>,
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Illinois at Urbana-Champaign<sup>1</sup>,</span>
                    <span class="author-block">The Ohio State University<sup>2</sup>,</span>
                    <span class="author-block">University of Science and Technology of China<sup>3</sup></span>
                      <!-- <br>Conferance name and year -->
                    </span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/yuanmengqi/AdvWeb" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/pipe_inference.jpg" alt="advweb pipeline"/>
      <h2 class="subtitle has-text-centered">
        AdvWeb is a black-box framework that exploits vulnerabilities in VLM-powered web agents by automatically generating and injecting adversarial prompts into web pages. It achieves high attack success rates while maintaining stealth and controllability, making these attacks significantly more flexible and efficient.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision Language Models (VLMs) have revolutionized the creation of generalist web agents, empowering them to autonomously complete diverse tasks on real-world websites, thereby boosting human efficiency and productivity. However, despite their remarkable capabilities, the safety and security of these agents against malicious attacks remain critically underexplored, raising significant concerns about their safe deployment.
            To uncover and exploit such vulnerabilities in web agents, we provide AdvWeb, a novel black-box attack framework designed against web agents. AdvWeb trains an adversarial prompter model that generates and injects adversarial prompts into web pages, misleading web agents into executing targeted adversarial actions such as inappropriate stock purchases or incorrect bank transactions—actions that could lead to severe real-world consequences. 
            With only black-box access to the web agent, we train and optimize the adversarial prompter model using Direct Policy Optimization (DPO), leveraging both successful and failed attack strings against the target agent. Unlike prior approaches, our adversarial string injection maintains stealth and control: (1) the appearance of the website remains unchanged before and after the attack, making it nearly impossible for users to detect tampering, and (2) attackers can modify specific substrings within the generated adversarial string to seamlessly change the attack objective (e.g., purchasing stocks from a different company), greatly enhancing attack flexibility and efficiency.
            We conduct extensive evaluations, demonstrating that AdvWeb achieves high success rates in attacking state-of-the-art GPT-4V-based VLM agents across various web tasks in black-box settings. Our findings expose critical vulnerabilities in current LLM/VLM-based agents, emphasizing the urgent need for developing more reliable web agents and implementing effective defenses against such adversarial threats.</p>
        </div>
      </div>
    </div>
  </div>

  <!--<div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/model.jpg" alt="foodsam pipeline"/>
       <h2 class="subtitle has-text-centered">
        The overview of our framework. FoodSAM contains three basic models: SAM, semantic segmenter, and object detector. SAM generates many class- agnostic binary masks, the semantic segmenter provides food category labels via mask-category match, and the object detector provides the non-food class for background masks. It then enhances the semantic mask via merge strategy and produces instance and panoptic results. Moreover, a seamless prompt-prior selection is integrated into the object detector to achieve promptable segmentation.
      </h2>
    </div>
  </div> -->
</section>
<!-- End paper abstract -->

<section class="section" id="method">
  <div class="container is-max-desktop content">
      <h2 class="title is-3">Method</h2>
      <div class="content has-text-centered">
        <img src="static/images/pipe_train_00.jpg" alt="model train" width="800" height="600"/>
      </div>
      <p> 
        (a) <strong>Automatic Attack and Feedback Collection Pipeline.</strong>
        We employ LLMs as an attack prompter, generating a set of n various diverse adversarial prompts. We then evaluate whether the attack against the black-box web agent is successful using these adversarial prompts, constructing positive signals and negative signals for reinforcement learning.
        <br>
        (b) <strong>AdvWeb Prompter Model Training.</strong> 
        Using the positive subsets, we perform the first stage SFT training. Leveraging both positive and negative feedback, we train the model in the second DPO stage.
      </p>
    </div>
  </div>
</section>

<section class="section" id="method">
  <div class="container is-max-desktop content">
      <h2 class="title is-3">Results</h2>
      <div class="content has-text-centered">
        <img src="static/images/ASR.png" alt="model train" width="600" height="350"/>
      </div>
      <p>
        A. <strong>Attack success rate (ASR) of different algorithms with different proprietary VLM backends across various website domains.</strong> 
        We compare our proposed AdvWeb algorithm with four strong baselines, and the attack performance of our algorithm is higher than that of the others.
        <br>
      </p>
      <div class="content has-text-centered">
        <img src="static/images/asr2.png" alt="model train" width="600" height="350"/>
      </div>
      <p> 
        B. <strong> Attack success rate (ASR) in the controllability test.</strong> 
        For successful attacks, the original attack targets are modified to alternative targets. We adjusted our method, AdvWeb, as well as the other four baselines to the controllable setting. The results show that AdvWeb’s performance is better than the other baselines.
        <br>
      </p>
      <div class="content has-text-centered">
        <img src="static/images/asr3.png" alt="model train" width="650" height="350"/>
      </div>
      <p> 
        C. <strong> Attack success rate (ASR) under different variations.</strong> 
        We take the successful attacks from the standard setting and evaluate their transferability across two conditions: changing the injection positions and modifying the HTML fields.
        <br>
      </p>
      <div class="content has-text-centered">
        <img src="static/images/asr4.png" alt="model train" width="650" height="350"/>
      </div>
      <p> 
        D. <strong>Attack success rate (ASR) comparison between transfer-based black-box attacks and AdvWeb with Gemini 1.5 backend.</strong> 
        Transfer-based attacks struggle with low ASR, as successful attacks on one model do not transfer well to other models. In contrast, AdvWeb, utilizing the RLAIF-based training paradigm with model feedback, achieves high ASR against black-box Gemini 1.5 models.
        <br>
      </p>
      <div class="content has-text-centered">
        <img src="static/images/asr5.png" alt="model train" width="600" height="450"/>
      </div>
      <p> 
        E. <strong>Comparison of AdvWeb attack success rate (ASR) with different training stages.</strong> 
        We show the ASR of AdvWeb when trained using only the SFT stage versus the full adversarial prompter model trained with both the SFT and DPO stages. The results demonstrate that incorporating the DPO stage, which leverages both positive and negative feedback, leads to a significant improvement in ASR compared to using SFT alone.
        <br>
      </p>
      <div class="content has-text-centered">
        <img src="static/images/pattern_difference_00.jpg" alt="model train" width="800" height="600"/>
      </div>
      <p> 
        F. <strong>Subtle differences in adversarial prompts lead to different attack results.</strong> 
        We show two pairs of adversarial prompts with minimal differences that result in different attack results. In the first pair, changing “you” to “I” makes the attack successful. In the second pair, adding the word “previous” successfully misleads the target agent.
      </p>
    </div>
  </div>
</section>

<!-- Image carousel -->
<!--<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title" style="text-align: center;">Visualization Comparison</h2>

      <div id="results-carousel" class="carousel results-carousel" style="text-align: center;">
        <div class="item">
          <img src="static/images/crossdomain.png" alt="semantic results"/>
          <h2 class="subtitle has-text-centered">
            Visualization on cross domain senarios. It is performed panoptic segmentation by FoodSAM.
          </h2>
        </div>
       <div class="item">
        <img src="static/images/semantic.jpg" alt="semantic results"/>
        <h2 class="subtitle has-text-centered">
          Visualization comparison with baseline and ground-truth on semantic segmentation. The difference is calculated between the enhanced and coarse.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/semantic_compare.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visualization comparison with SSA and RAM on semantic segmentation. SSA and RAM may output the instance information and their results are obtained by the public repository, here we only discuss semantic results on food.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/instance_compare.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visualization comparison with RAM on instance segmentation. RAM may output the non-food instance information, here we only discuss the semantic results on food.
       </h2>
     </div>
     <div class="item">
      <img src="static/images/panoptic_compare.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Visualization comparison with RAM, SEEM and ours on panoptic segmentation. The visualization results are obtained from their public code repository.
      </h2>
    </div>
    <div class="item">
      <img src="static/images/prompt_vis.jpg" alt="prompt visualization"/>
      <h2 class="subtitle has-text-centered">
        Visualization results on promptable segmentation. From left to right: input, double point prompts, double box prompts
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->








<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc
  </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>